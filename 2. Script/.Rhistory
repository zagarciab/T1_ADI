number = 5,
index = index,
indexOut = indexOut,
search = "random"
)
# Entrenar
set.seed(123)
modelo_xgb_espacial <- train(
formula_modelo,
data = train_factors,
method = "xgbTree",
trControl = ctrl_espacial,
tuneGrid = grid_xgb,
metric = "RMSE",
verbosity = 0
)
# Cargar paquetes
pacman::p_load(caret, xgboost, Metrics)
library(sf)
library(dplyr)
train_espacial <- train_localidades_sf %>%
select(property_id, geometry) %>%
inner_join(train_factors, by = "property_id")
library(spatialsample)
set.seed(123)
block_folds_EN <- spatial_block_cv(train_espacial, v = 5)
library(ggplot2)
autoplot(block_folds_EN)
# Definir grid
grid_xgb <- expand.grid(
nrounds = c(100, 250),
max_depth = c(3, 5, 7),
eta = c(0.1, 0.05),
gamma = c(0, 1),
colsample_bytree = 0.8,
min_child_weight = 5,
subsample = 0.8
)
library(rsample)
index <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(analysis(split)))
})
indexOut <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(assessment(split)))
})
# Control
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut,
search = "random"
)
# Entrenar
set.seed(123)
modelo_xgb_espacial <- train(
formula_modelo,
data = train_factors,
method = "xgbTree",
trControl = ctrl_espacial,
tuneGrid = grid_xgb,
metric = "RMSE",
verbosity = 0
)
# Asegurar que las variables categóricas en test tengan los mismos niveles que en train_factors
for (col in cols_factor) {
test[[col]] <- factor(test[[col]], levels = levels(train_factors[[col]]))
}
# Hacer las predicciones
predicciones_xgboost_espacial <- predict(modelo_xgb_espacial, newdata = test)
# Guardar resultados con predicción
resultados_prediccion_boosting_espacial <- test %>%
mutate(predicted_price_xgboost_espacial = predicciones_xgboost_espacial)
# Preparar formato para Kaggle (o tu entrega)
pred_boosting_espacial <- resultados_prediccion_boosting_espacial %>%
select(property_id, predicted_price_xgboost_espacial) %>%
rename(price = predicted_price_xgboost_espacial)
View(pred_boosting_espacial)
View(pred_boosting1)
# Cargar paquetes
pacman::p_load(caret, xgboost, Metrics)
library(sf)
library(dplyr)
train_espacial <- train_localidades_sf %>%
select(property_id, geometry) %>%
inner_join(train_factors, by = "property_id")
library(spatialsample)
set.seed(123)
block_folds_EN <- spatial_block_cv(train_espacial, v = 5)
library(ggplot2)
autoplot(block_folds_EN)
# Definir grid
grid_xgb <- expand.grid(
nrounds = c(100, 250),
max_depth = c(3, 5, 7),
eta = c(0.1, 0.05),
gamma = c(0, 1),
colsample_bytree = c(0.6, 0.8),
min_child_weight = 5,
subsample = 0.8
)
library(rsample)
index <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(analysis(split)))
})
indexOut <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(assessment(split)))
})
# Control
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut,
search = "random"
)
# Entrenar
set.seed(123)
modelo_xgb_espacial <- train(
formula_modelo,
data = train_factors,
method = "xgbTree",
trControl = ctrl_espacial,
tuneGrid = grid_xgb,
metric = "RMSE",
verbosity = 0
)
# Asegurar que las variables categóricas en test tengan los mismos niveles que en train_factors
for (col in cols_factor) {
test[[col]] <- factor(test[[col]], levels = levels(train_factors[[col]]))
}
# Hacer las predicciones
predicciones_xgboost_espacial <- predict(modelo_xgb_espacial, newdata = test)
# Guardar resultados con predicción
resultados_prediccion_boosting_espacial <- test %>%
mutate(predicted_price_xgboost_espacial = predicciones_xgboost_espacial)
# Preparar formato para Kaggle (o tu entrega)
pred_boosting_espacial <- resultados_prediccion_boosting_espacial %>%
select(property_id, predicted_price_xgboost_espacial) %>%
rename(price = predicted_price_xgboost_espacial)
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut,
savePredictions = "final"
)
library(caretEnsemble)
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut,
savePredictions = "final"
)
install.packages("caretEnsemble", dependencies = TRUE)
library(caretEnsemble)
modelos_base <- caretList(
formula_modelo,
data = train_factors,
trControl = ctrl_espacial,
metric = "RMSE",
tuneList = list(
xgb = caretModelSpec(method = "xgbTree", tuneGrid = grid_xgb),
arbol = caretModelSpec(method = "rpart"),
lineal = caretModelSpec(method = "lm")
)
)
superlearner <- caretEnsemble(
modelos_base,
metric = "RMSE",
trControl = trainControl(number = 5)
)
predicciones_superlearner <- predict(superlearner, newdata = test)
View(predicciones_superlearner)
View(pred_boosting_espacial)
predicciones_superlearner <- predict(superlearner, newdata = test) %>%
select(property_id, predicted_price_superlearner) %>%
rename(price = predicted_price_superlearner)
# Predecir precios con el ensamble
predicciones_superlearner <- predict(superlearner, newdata = test)
# Guardar resultados con property_id
pred_superlearner <- test %>%
mutate(price = predicciones_superlearner) %>%
select(property_id, price)
View(pred_superlearner)
library(tidymodels)
install.packages("rlang")
library(tidymodels)
# Instalar y cargar el paquetes
if (!require("pacman")) install.packages("pacman")
library(pacman)
if (!require("MLmetrics")) install.packages("MLmetrics")
library(MLmetrics)
# Usar pacman para cargar (e instalar si es necesario) los paquetes
p_load(tidyverse,   # Manipulación y visualización de datos
dplyr,       # Manipulación de datos
ggplot2,     # Visualización de datos en gráficas
readr,       # Importación de datos
stargazer,   # Formato para tablas
utils,       # Lctura de archivos y manipulación de datos
skimr,       # Resumen estadístico
caret,       # Creación y validación de modelos predictivos
glmnet,      # Modelos de regresión penalizados (Ridge, Lasso)
xgboost,     # Implementación de Gradient Boosting
rpart,       # Árboles de decisión
rpart.plot,  # Visualización de árboles generados por rpart
pROC,        # Curvas ROC y métricas
Metrics,     # Métricas de evaluación
httr,        # Solicitudes http
rio,         # Facilidad para importar data
plotly,      # Gráficos interactivos
osmdata,     # Obtener información de open street maps
sf,          # Leer/escribir/manipular datos espaciales
leaflet,     # Mapas interactivos
gridExtra,   # Graficar en grid
tmaptools,   # Geocode_OMS()
geosphere,   # Calcular distancias geográficas como Haversine
tidymodels,  # Carga recipes, parsnip, rsample, tune, y otros paquetes relacionados
spatialsample, # Muestreo espacial
vip
)
install.packages("rlang", type = "source")
install.packages("rlang", type = "source")
install.packages("rlang", type = "source")
install.packages("rlang", type = "source")
install.packages("rlang", type = "source")
knitr::opts_chunk$set(echo = TRUE)
# Instalar si no lo tienes
install.packages("haven")
# Cargar librería
library(haven)
# Leer archivo Stata
data <- read_dta("C:/Users/njaco/OneDrive/Documentos/Mestría en Economía Aplicada/Semestre 4/Evaluación de Impacto/corruption_SV.dta")
# Ver los primeros registros
head(data)
View(data)
modelo_1 <- lm(prop ~ Corrupt, data = data)
modelo_1 <- lm(prop ~ Corrupt, data = data)
summary(modelo_1)
modelo_2 <- lm(prop ~ Corrupt + Audiada + grade + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG, data = data)
modelo_2 <- lm(prop ~ Corrupt + Auditada + grade + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG, data = data)
modelo_2 <- lm(prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG, data = data)
summary(modelo_2)
as.factor(GradoSecundaria)
as.factor(data, GradoSecundaria)
data$GradoSecundaria <- as.factor(data$GradoSecundaria)
modelo_2 <- lm(prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG, data = data)
summary(modelo_2)
modelo_3 <- lm(prop ~ Corrupt + clavedelaescuela + year, data = data)
modelo_3 <- lm(prop ~ Corrupt + clavedelaescuela + year, data = data, model = "within")
install.packages("plm")
library(plm)
# Definir datos de panel (id = escuela, time = año)
pdata <- pdata.frame(data, index = c("clavedelaescuela", "year"))
# Modelo con efectos fijos por escuela
modelo_3 <- plm(prop ~ Corrupt, data = pdata, model = "within", effect = "individual")
summary(modelo_3)
knitr::opts_chunk$set(echo = TRUE)
install.packages("plm")
library(plm)
# Definir datos de panel (id = escuela, time = año)
pdata <- pdata.frame(data, index = c("clavedelaescuela", "year"))
# Modelo con efectos fijos por escuela
modelo_3 <- plm(prop ~ Corrupt, data = pdata, model = "within", effect = "individual")
summary(modelo_3)
# Modelo con efectos fijos por año
modelo_4 <- plm(prop ~ Corrupt, data = pdata, model = "within", effect = "time")
summary(modelo_4)
# Modelo con efectos fijos dobles (escuela y año)
modelo_5 <- plm(prop ~ Corrupt, data = pdata, model = "within", effect = "twoways")
summary(modelo_5)
View(pdata)
View(pdata)
# Liberias y paquetes
install.packages("haven") # Archivos .dta
library(haven)
install.packages("plm")
library(plm)
# Datos .dta
url_data <- "https://github.com/zagarciab/T1_ADI/raw/main/3.%20Data/corruption_SV.dta"
base <- read_dta(url_data)
lm1<- lm (prop ~ Corrupt, base)
summary(lm1)
# Convertir a factor
base$GradoSecundaria <- as_factor(base$GradoSecundaria)
# Convertir a factor
base$GradoSecundaria <- as.factor(base$GradoSecundaria)
# Regresión por MCO con controles
lm2 <- lm (prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG , base)
summary(lm2)
# Matriz con efectos fijos
m_base <- pdata.frame(base, index = c("clavedelaescuela", "year"))
# Matriz con efectos fijos
m_base <- pdata.frame(base, index = c("clavedelaescuela", "year"))
# Matriz con efectos fijos
m_base <- pdata.frame(base, index = c("clavedelaescuela", "year"))
# Liberias y paquetes
install.packages("haven") # Archivos .dta
library(haven)
install.packages("plm")
library(plm)
# Datos .dta
url_data <- "https://github.com/zagarciab/T1_ADI/raw/main/3.%20Data/corruption_SV.dta"
base <- read_dta(url_data)
# Matriz con efectos fijos
m_base <- pdata.frame(base, index = c("clavedelaescuela", "year"))
# Modelo de efectos fijos (within estimator)
m_ef1 <- plm(prop ~ Corrupt,
data = m_base,
model = "within")
summary(m_ef1)
# Corregir, hay multicolinealidad perfecta
m_ef2 <- plm(prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG,
data = m_base,
model = "within")
summary(m_ef2)
View(base)
# Modelo de efectos fijos extra con solo grado de control (within estimator)
m_extra <- plm(prop ~ Corrupt + GradoSecundaria,
data = m_base,
model = "within")
summary(m_extra)
# Instalar si no lo tienes
# install.packages("stargazer")
library(stargazer)
# Tabla tipo artículo mostrando solo el coeficiente Corrupt
stargazer(lm1, lm2, m_ef1, m_extra,
type = "text",             # Para consola; cambiar a "html" o "latex" si quieres
keep = "Corrupt",          # Solo muestra el coeficiente de interés
column.labels = c("Solo Corrupt",
"Controles",
"Efectos fijos",
"Controles + EF grado"),
dep.var.labels = "Proporción",
covariate.labels = "Corrupción",
digits = 3,
no.space = TRUE,
title = "Resultados de las regresiones",
notes = c("Modelo (1): solo variable de interés",
"Modelo (2): controles incluidos",
"Modelo (3) y (4): efectos fijos por escuela y año",
"Solo se reporta el coeficiente de Corrupt"))
# La tabla debe tener el formato de presentación tipo artículo y estar completamente en español. Asegúrense de que esta tabla presente únicamente el coeficiente asociado a la variable de interés – i.e., no presente los coeficientes asociados a los controles, el intercepto o los efectos fijos. Debe ser claro, sin embargo, qué es incluido en cada columna.
library(stargazer)
stargazer(lm1, lm2, m_ef1, m_extra,
type = "text",              # Cambiar a "html" o "latex" si quieres
keep = "Corrupt",           # Solo muestra el coeficiente de interés
column.labels = c("(1)", "(2)", "(3)", "(4)"),
dep.var.labels = "Proporción",
covariate.labels = "Corrupción",
digits = 3,
no.space = TRUE,
title = "Resultados de las regresiones",
add.lines = list(
c("Controles", "No", "Sí", "No", "Sí"),
c("Efectos fijos", "No", "No", "Sí", "Sí")
),
notes = "Errores estándar entre paréntesis. Solo se reporta el coeficiente de 'Corrupt'.")
# La tabla debe tener el formato de presentación tipo artículo y estar completamente en español. Asegúrense de que esta tabla presente únicamente el coeficiente asociado a la variable de interés – i.e., no presente los coeficientes asociados a los controles, el intercepto o los efectos fijos. Debe ser claro, sin embargo, qué es incluido en cada columna.
# Modelo de efectos fijos extra con solo grado de control (within estimator)
m_extra <- plm(prop ~ Corrupt + GradoSecundaria,
data = m_base,
model = "within")
summary(m_extra)
# Convertir a factor
base$GradoSecundaria <- as.factor(base$GradoSecundaria)
# Modelo de efectos fijos extra con solo grado de control (within estimator)
m_extra <- plm(prop ~ Corrupt + GradoSecundaria,
data = m_base,
model = "within")
summary(m_extra)
# Liberias y paquetes
install.packages("haven") # Archivos .dta
install.packages("plm")
install.packages("skimr")
install.packages("dplyr")
# Liberias y paquetes
install.packages("haven") # Archivos .dta
install.packages("plm")
install.packages("skimr")
install.packages("dplyr")
install.packages("skimr")
library(haven)
library(plm)
library(skimr)
library(dplyr)
library(haven)
library(ggplot2)
# Carga de datos .dta
url_data <- "https://github.com/zagarciab/T1_ADI/raw/main/3.%20Data/corruption_SV.dta"
base <- read_dta(url_data)
# Estructura de datos y estadísticas
str(base)
skim(base)
# Imputación de missing values
## Histogramas
ggplot(base, aes(prop)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(base$prop, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(base$prop, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 1 - Histograma de Prop ") +
theme_bw() +
theme(plot.title = element_text(size = 18))
ggplot(base, aes(unauthorized)) +
geom_histogram(color = "#000000", fill = "#0099F8") +
geom_vline(xintercept = median(base$unauthorized, na.rm = TRUE), linetype = "dashed", color = "red") +
geom_vline(xintercept = mean(base$unauthorized, na.rm = TRUE), linetype = "dashed", color = "blue") +
ggtitle("GRÁFICA 1 - Histograma de unauthorized ") +
theme_bw() +
theme(plot.title = element_text(size = 18))
## Imputación de missing values con la mediana para Prop
base <- base  %>%
mutate(prop = ifelse(is.na(prop) == TRUE,
median(base$prop, na.rm = TRUE) , prop),
unauthorized = ifelse(is.na(unauthorized) == TRUE,
median(base$unauthorized, na.rm = TRUE),
unauthorized))
## Imputación variables dicotómica con moda
moda_auditada <- base %>%
filter(!is.na(Auditada)) %>%
count(Auditada) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(Auditada)
moda_AlreadyAudited <- base %>%
filter(!is.na(AlreadyAudited)) %>%
count(AlreadyAudited) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(AlreadyAudited)
moda_CorruptPast <- base %>%
filter(!is.na(CorruptPast)) %>%
count(CorruptPast) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(CorruptPast)
moda_Corrupt <- base %>%
filter(!is.na(Corrupt)) %>%
count(Corrupt) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(Corrupt)
moda_HOMI <- base %>%
filter(!is.na(HOMI_CAP_MUN)) %>%
count(HOMI_CAP_MUN) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(HOMI_CAP_MUN)
moda_grado <- base %>%
filter(!is.na(GradoSecundaria)) %>%
count(GradoSecundaria) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(GradoSecundaria)
moda_grado <- base %>%
filter(!is.na(GradoSecundaria)) %>%
count(GradoSecundaria) %>%
arrange(desc(n)) %>%
slice(1) %>%
pull(GradoSecundaria)
base <- base %>%
mutate(Auditada = ifelse(is.na(Auditada) == TRUE,
moda_auditada, Auditada),
AlreadyAudited = ifelse(is.na(AlreadyAudited) == TRUE,
moda_AlreadyAudited, AlreadyAudited),
CorruptPast = ifelse(is.na(CorruptPast) == TRUE,
moda_CorruptPast, CorruptPast),
Corrupt = ifelse(is.na(Corrupt) == TRUE,
moda_Corrupt, Corrupt),
HOMI_CAP_MUN = ifelse(is.na(HOMI_CAP_MUN)  == TRUE,
moda_HOMI, HOMI_CAP_MUN),
GradoSecundaria = ifelse(is.na(GradoSecundaria)  == TRUE,
moda_grado, GradoSecundaria))
## Convertir a factor variables categoricas
var_factor <- c("clavedelaescuela", "turno", "GradoSecundaria", "year",
"clave_mun", "Auditada", "AlreadyAudited", "CorruptPast",
"Corrupt")
base <- base %>%
mutate(across(all_of(var_factor), as.factor))
lm1<- lm (prop ~ Corrupt, base)
summary(lm1)
# Regresión por MCO con controles
lm2 <- lm (prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG , base)
summary(lm2)
# Matriz con efectos fijos
m_base <- pdata.frame(base, index = c("clavedelaescuela", "year"))
# Modelo de efectos fijos (within estimator)
m_ef1 <- plm(prop ~ Corrupt,
data = m_base,
model = "within", effect = "twoways") # Estimación de modelo de EF y se especifica que se controle por ambas dimensiones, escuela y años.
summary(m_ef1)
m_ef2 <- plm(prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN,
data = m_base,
model = "within", effect = "twoways")
summary(m_ef2)
m_extra <- plm(prop ~ Corrupt + Auditada + GradoSecundaria + AlreadyAudited + CorruptPast + HOMI_CAP_MUN,
data = m_base,
model = "within", effect = "twoways")
summary(m_extra)
m_ef2 <- plm(prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN,
data = m_base,
model = "within", effect = "twoways")
summary(m_ef2, waldf = FALSE)
install.packages(c("haven","plm","skimr","dplyr","ggplot2"))
library(haven)
library(plm)
library(skimr)
library(dplyr)
library(haven)
library(ggplot2)
install.packages(c("haven", "plm", "skimr", "dplyr", "ggplot2"))
