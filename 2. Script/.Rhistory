metric = "RMSE",
verbosity = 0
)
# Cargar paquetes
pacman::p_load(caret, xgboost, Metrics)
library(sf)
library(dplyr)
train_espacial <- train_localidades_sf %>%
select(property_id, geometry) %>%
inner_join(train_factors, by = "property_id")
library(spatialsample)
set.seed(123)
block_folds_EN <- spatial_block_cv(train_espacial, v = 5)
library(ggplot2)
autoplot(block_folds_EN)
#Definir grid
grid_xgb <- expand.grid(
nrounds = c(100, 250),
max_depth = c(3, 5),
eta = c(0.1, 0.05),
gamma = c(0, 1),
colsample_bytree = c(0.8),
min_child_weight = c(5),
subsample = c(0.8)
)
library(rsample)
index <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(analysis(split)))
})
indexOut <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(assessment(split)))
})
# Control
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut
)
# Entrenar
set.seed(123)
modelo_xgb_espacial <- train(
formula_modelo,
data = train_factors,
method = "xgbTree",
trControl = ctrl_espacial,
tuneGrid = grid_xgb,
metric = "RMSE",
verbosity = 0
)
# Asegurar que las variables categóricas en test tengan los mismos niveles que en train_factors
for (col in cols_factor) {
test[[col]] <- factor(test[[col]], levels = levels(train_factors[[col]]))
}
# Hacer las predicciones
predicciones_xgboost_espacial <- predict(modelo_xgb_espacial, newdata = test)
# Guardar resultados con predicción
resultados_prediccion_boosting_espacial <- test %>%
mutate(predicted_price_xgboost_espacial = predicciones_xgboost_espacial)
# Preparar formato para Kaggle (o tu entrega)
pred_boosting_espacial <- resultados_prediccion_boosting_espacial %>%
select(property_id, predicted_price_xgboost_espacial) %>%
rename(price = predicted_price_xgboost_espacial)
View(test_aptos)
View(resultados_prediccion_boosting)
View(resultados_prediccion_boosting_espacial)
# Descargar archivo
write.csv(pred_boosting_espacial,
"C:/Users/njaco/OneDrive/Documentos/10-04_G4_BOOSTING22.csv", row.names = FALSE,
quote = FALSE)
# Cargar paquetes
pacman::p_load(caret, xgboost, Metrics)
library(sf)
library(dplyr)
train_espacial <- train_localidades_sf %>%
select(property_id, geometry) %>%
inner_join(train_factors, by = "property_id")
library(spatialsample)
set.seed(123)
block_folds_EN <- spatial_block_cv(train_espacial, v = 5)
library(ggplot2)
autoplot(block_folds_EN)
# Definir grid
grid_xgb <- expand.grid(
nrounds = c(100, 250, 500),
max_depth = c(3, 5, 7),
eta = c(0.3, 0.1, 0.05),
gamma = c(0, 1, 5),
colsample_bytree = c(0.6, 0.8),
min_child_weight = c(1, 5, 10),
subsample = c(0.6, 0.8, 1)
library(rsample)
# Cargar paquetes
pacman::p_load(caret, xgboost, Metrics)
library(sf)
library(dplyr)
train_espacial <- train_localidades_sf %>%
select(property_id, geometry) %>%
inner_join(train_factors, by = "property_id")
library(spatialsample)
set.seed(123)
block_folds_EN <- spatial_block_cv(train_espacial, v = 5)
library(ggplot2)
autoplot(block_folds_EN)
# Definir grid
grid_xgb <- expand.grid(
nrounds = c(100, 250, 500),
max_depth = c(3, 5, 7),
eta = c(0.3, 0.1, 0.05),
gamma = c(0, 1, 5),
colsample_bytree = c(0.6, 0.8),
min_child_weight = c(1, 5, 10),
subsample = c(0.6, 0.8, 1)
)
library(rsample)
index <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(analysis(split)))
})
indexOut <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(assessment(split)))
})
# Control
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut,
search = "random"
)
# Entrenar
set.seed(123)
modelo_xgb_espacial <- train(
formula_modelo,
data = train_factors,
method = "xgbTree",
trControl = ctrl_espacial,
tuneGrid = grid_xgb,
metric = "RMSE",
verbosity = 0
)
# Cargar paquetes
pacman::p_load(caret, xgboost, Metrics)
library(sf)
library(dplyr)
train_espacial <- train_localidades_sf %>%
select(property_id, geometry) %>%
inner_join(train_factors, by = "property_id")
library(spatialsample)
set.seed(123)
block_folds_EN <- spatial_block_cv(train_espacial, v = 5)
library(ggplot2)
autoplot(block_folds_EN)
# Definir grid
grid_xgb <- expand.grid(
nrounds = c(100, 250),
max_depth = c(3, 5, 7),
eta = c(0.1, 0.05),
gamma = c(0, 1),
colsample_bytree = 0.8,
min_child_weight = 5,
subsample = 0.8
)
library(rsample)
index <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(analysis(split)))
})
indexOut <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(assessment(split)))
})
# Control
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut,
search = "random"
)
# Entrenar
set.seed(123)
modelo_xgb_espacial <- train(
formula_modelo,
data = train_factors,
method = "xgbTree",
trControl = ctrl_espacial,
tuneGrid = grid_xgb,
metric = "RMSE",
verbosity = 0
)
# Asegurar que las variables categóricas en test tengan los mismos niveles que en train_factors
for (col in cols_factor) {
test[[col]] <- factor(test[[col]], levels = levels(train_factors[[col]]))
}
# Hacer las predicciones
predicciones_xgboost_espacial <- predict(modelo_xgb_espacial, newdata = test)
# Guardar resultados con predicción
resultados_prediccion_boosting_espacial <- test %>%
mutate(predicted_price_xgboost_espacial = predicciones_xgboost_espacial)
# Preparar formato para Kaggle (o tu entrega)
pred_boosting_espacial <- resultados_prediccion_boosting_espacial %>%
select(property_id, predicted_price_xgboost_espacial) %>%
rename(price = predicted_price_xgboost_espacial)
View(pred_boosting_espacial)
View(pred_boosting1)
# Cargar paquetes
pacman::p_load(caret, xgboost, Metrics)
library(sf)
library(dplyr)
train_espacial <- train_localidades_sf %>%
select(property_id, geometry) %>%
inner_join(train_factors, by = "property_id")
library(spatialsample)
set.seed(123)
block_folds_EN <- spatial_block_cv(train_espacial, v = 5)
library(ggplot2)
autoplot(block_folds_EN)
# Definir grid
grid_xgb <- expand.grid(
nrounds = c(100, 250),
max_depth = c(3, 5, 7),
eta = c(0.1, 0.05),
gamma = c(0, 1),
colsample_bytree = c(0.6, 0.8),
min_child_weight = 5,
subsample = 0.8
)
library(rsample)
index <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(analysis(split)))
})
indexOut <- lapply(block_folds_EN$splits, function(split) {
as.integer(rownames(assessment(split)))
})
# Control
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut,
search = "random"
)
# Entrenar
set.seed(123)
modelo_xgb_espacial <- train(
formula_modelo,
data = train_factors,
method = "xgbTree",
trControl = ctrl_espacial,
tuneGrid = grid_xgb,
metric = "RMSE",
verbosity = 0
)
# Asegurar que las variables categóricas en test tengan los mismos niveles que en train_factors
for (col in cols_factor) {
test[[col]] <- factor(test[[col]], levels = levels(train_factors[[col]]))
}
# Hacer las predicciones
predicciones_xgboost_espacial <- predict(modelo_xgb_espacial, newdata = test)
# Guardar resultados con predicción
resultados_prediccion_boosting_espacial <- test %>%
mutate(predicted_price_xgboost_espacial = predicciones_xgboost_espacial)
# Preparar formato para Kaggle (o tu entrega)
pred_boosting_espacial <- resultados_prediccion_boosting_espacial %>%
select(property_id, predicted_price_xgboost_espacial) %>%
rename(price = predicted_price_xgboost_espacial)
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut,
savePredictions = "final"
)
library(caretEnsemble)
ctrl_espacial <- trainControl(
method = "cv",
number = 5,
index = index,
indexOut = indexOut,
savePredictions = "final"
)
install.packages("caretEnsemble", dependencies = TRUE)
library(caretEnsemble)
modelos_base <- caretList(
formula_modelo,
data = train_factors,
trControl = ctrl_espacial,
metric = "RMSE",
tuneList = list(
xgb = caretModelSpec(method = "xgbTree", tuneGrid = grid_xgb),
arbol = caretModelSpec(method = "rpart"),
lineal = caretModelSpec(method = "lm")
)
)
superlearner <- caretEnsemble(
modelos_base,
metric = "RMSE",
trControl = trainControl(number = 5)
)
predicciones_superlearner <- predict(superlearner, newdata = test)
View(predicciones_superlearner)
View(pred_boosting_espacial)
predicciones_superlearner <- predict(superlearner, newdata = test) %>%
select(property_id, predicted_price_superlearner) %>%
rename(price = predicted_price_superlearner)
# Predecir precios con el ensamble
predicciones_superlearner <- predict(superlearner, newdata = test)
# Guardar resultados con property_id
pred_superlearner <- test %>%
mutate(price = predicciones_superlearner) %>%
select(property_id, price)
View(pred_superlearner)
library(tidymodels)
install.packages("rlang")
library(tidymodels)
# Instalar y cargar el paquetes
if (!require("pacman")) install.packages("pacman")
library(pacman)
if (!require("MLmetrics")) install.packages("MLmetrics")
library(MLmetrics)
# Usar pacman para cargar (e instalar si es necesario) los paquetes
p_load(tidyverse,   # Manipulación y visualización de datos
dplyr,       # Manipulación de datos
ggplot2,     # Visualización de datos en gráficas
readr,       # Importación de datos
stargazer,   # Formato para tablas
utils,       # Lctura de archivos y manipulación de datos
skimr,       # Resumen estadístico
caret,       # Creación y validación de modelos predictivos
glmnet,      # Modelos de regresión penalizados (Ridge, Lasso)
xgboost,     # Implementación de Gradient Boosting
rpart,       # Árboles de decisión
rpart.plot,  # Visualización de árboles generados por rpart
pROC,        # Curvas ROC y métricas
Metrics,     # Métricas de evaluación
httr,        # Solicitudes http
rio,         # Facilidad para importar data
plotly,      # Gráficos interactivos
osmdata,     # Obtener información de open street maps
sf,          # Leer/escribir/manipular datos espaciales
leaflet,     # Mapas interactivos
gridExtra,   # Graficar en grid
tmaptools,   # Geocode_OMS()
geosphere,   # Calcular distancias geográficas como Haversine
tidymodels,  # Carga recipes, parsnip, rsample, tune, y otros paquetes relacionados
spatialsample, # Muestreo espacial
vip
)
install.packages("rlang", type = "source")
install.packages("rlang", type = "source")
install.packages("rlang", type = "source")
install.packages("rlang", type = "source")
install.packages("rlang", type = "source")
knitr::opts_chunk$set(echo = TRUE)
# Instalar si no lo tienes
install.packages("haven")
# Cargar librería
library(haven)
# Leer archivo Stata
data <- read_dta("C:/Users/njaco/OneDrive/Documentos/Mestría en Economía Aplicada/Semestre 4/Evaluación de Impacto/corruption_SV.dta")
# Ver los primeros registros
head(data)
View(data)
modelo_1 <- lm(prop ~ Corrupt, data = data)
modelo_1 <- lm(prop ~ Corrupt, data = data)
summary(modelo_1)
modelo_2 <- lm(prop ~ Corrupt + Audiada + grade + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG, data = data)
modelo_2 <- lm(prop ~ Corrupt + Auditada + grade + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG, data = data)
modelo_2 <- lm(prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG, data = data)
summary(modelo_2)
as.factor(GradoSecundaria)
as.factor(data, GradoSecundaria)
data$GradoSecundaria <- as.factor(data$GradoSecundaria)
modelo_2 <- lm(prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG, data = data)
summary(modelo_2)
modelo_3 <- lm(prop ~ Corrupt + clavedelaescuela + year, data = data)
modelo_3 <- lm(prop ~ Corrupt + clavedelaescuela + year, data = data, model = "within")
install.packages("plm")
library(plm)
# Definir datos de panel (id = escuela, time = año)
pdata <- pdata.frame(data, index = c("clavedelaescuela", "year"))
# Modelo con efectos fijos por escuela
modelo_3 <- plm(prop ~ Corrupt, data = pdata, model = "within", effect = "individual")
summary(modelo_3)
knitr::opts_chunk$set(echo = TRUE)
install.packages("plm")
library(plm)
# Definir datos de panel (id = escuela, time = año)
pdata <- pdata.frame(data, index = c("clavedelaescuela", "year"))
# Modelo con efectos fijos por escuela
modelo_3 <- plm(prop ~ Corrupt, data = pdata, model = "within", effect = "individual")
summary(modelo_3)
# Modelo con efectos fijos por año
modelo_4 <- plm(prop ~ Corrupt, data = pdata, model = "within", effect = "time")
summary(modelo_4)
# Modelo con efectos fijos dobles (escuela y año)
modelo_5 <- plm(prop ~ Corrupt, data = pdata, model = "within", effect = "twoways")
summary(modelo_5)
View(pdata)
View(pdata)
# Liberias y paquetes
install.packages("haven") # Archivos .dta
library(haven)
install.packages("plm")
library(plm)
# Datos .dta
url_data <- "https://github.com/zagarciab/T1_ADI/raw/main/3.%20Data/corruption_SV.dta"
base <- read_dta(url_data)
lm1<- lm (prop ~ Corrupt, base)
summary(lm1)
# Convertir a factor
base$GradoSecundaria <- as_factor(base$GradoSecundaria)
# Convertir a factor
base$GradoSecundaria <- as.factor(base$GradoSecundaria)
# Regresión por MCO con controles
lm2 <- lm (prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG , base)
summary(lm2)
# Matriz con efectos fijos
m_base <- pdata.frame(base, index = c("clavedelaescuela", "year"))
# Matriz con efectos fijos
m_base <- pdata.frame(base, index = c("clavedelaescuela", "year"))
# Matriz con efectos fijos
m_base <- pdata.frame(base, index = c("clavedelaescuela", "year"))
# Liberias y paquetes
install.packages("haven") # Archivos .dta
library(haven)
install.packages("plm")
library(plm)
# Datos .dta
url_data <- "https://github.com/zagarciab/T1_ADI/raw/main/3.%20Data/corruption_SV.dta"
base <- read_dta(url_data)
# Matriz con efectos fijos
m_base <- pdata.frame(base, index = c("clavedelaescuela", "year"))
# Modelo de efectos fijos (within estimator)
m_ef1 <- plm(prop ~ Corrupt,
data = m_base,
model = "within")
summary(m_ef1)
# Corregir, hay multicolinealidad perfecta
m_ef2 <- plm(prop ~ Corrupt + Auditada + GradoSecundaria + PartidoDesf + AlreadyAudited + CorruptPast + HOMI_CAP_MUN + total + MismoPartidoG,
data = m_base,
model = "within")
summary(m_ef2)
View(base)
# Modelo de efectos fijos extra con solo grado de control (within estimator)
m_extra <- plm(prop ~ Corrupt + GradoSecundaria,
data = m_base,
model = "within")
summary(m_extra)
# Instalar si no lo tienes
# install.packages("stargazer")
library(stargazer)
# Tabla tipo artículo mostrando solo el coeficiente Corrupt
stargazer(lm1, lm2, m_ef1, m_extra,
type = "text",             # Para consola; cambiar a "html" o "latex" si quieres
keep = "Corrupt",          # Solo muestra el coeficiente de interés
column.labels = c("Solo Corrupt",
"Controles",
"Efectos fijos",
"Controles + EF grado"),
dep.var.labels = "Proporción",
covariate.labels = "Corrupción",
digits = 3,
no.space = TRUE,
title = "Resultados de las regresiones",
notes = c("Modelo (1): solo variable de interés",
"Modelo (2): controles incluidos",
"Modelo (3) y (4): efectos fijos por escuela y año",
"Solo se reporta el coeficiente de Corrupt"))
# La tabla debe tener el formato de presentación tipo artículo y estar completamente en español. Asegúrense de que esta tabla presente únicamente el coeficiente asociado a la variable de interés – i.e., no presente los coeficientes asociados a los controles, el intercepto o los efectos fijos. Debe ser claro, sin embargo, qué es incluido en cada columna.
library(stargazer)
stargazer(lm1, lm2, m_ef1, m_extra,
type = "text",              # Cambiar a "html" o "latex" si quieres
keep = "Corrupt",           # Solo muestra el coeficiente de interés
column.labels = c("(1)", "(2)", "(3)", "(4)"),
dep.var.labels = "Proporción",
covariate.labels = "Corrupción",
digits = 3,
no.space = TRUE,
title = "Resultados de las regresiones",
add.lines = list(
c("Controles", "No", "Sí", "No", "Sí"),
c("Efectos fijos", "No", "No", "Sí", "Sí")
),
notes = "Errores estándar entre paréntesis. Solo se reporta el coeficiente de 'Corrupt'.")
# La tabla debe tener el formato de presentación tipo artículo y estar completamente en español. Asegúrense de que esta tabla presente únicamente el coeficiente asociado a la variable de interés – i.e., no presente los coeficientes asociados a los controles, el intercepto o los efectos fijos. Debe ser claro, sin embargo, qué es incluido en cada columna.
# Modelo de efectos fijos extra con solo grado de control (within estimator)
m_extra <- plm(prop ~ Corrupt + GradoSecundaria,
data = m_base,
model = "within")
summary(m_extra)
# Convertir a factor
base$GradoSecundaria <- as.factor(base$GradoSecundaria)
# Modelo de efectos fijos extra con solo grado de control (within estimator)
m_extra <- plm(prop ~ Corrupt + GradoSecundaria,
data = m_base,
model = "within")
summary(m_extra)
install.packages("xfun")
packageVersion("xfun")
library(ggplot2) # ejemplo de paquete que uses
library(dplyr)   # otro paquete común
library(xfun)
xfun::session_info()
# Liberias y paquetes
install.packages("haven") # Archivos .dta
install.packages("plm")
install.packages("skimr")
install.packages("dplyr")
install.packages("ggplot2")
library(haven)
library(plm)
install.packages("dplyr")
install.packages("ggplot2")
